# Sub PJT1 & Sub PJT 2 전체 정리

> Sub PJT1과 Sub PJT2의 전체 주요 기술들을 정리해 보았습니다.

#### 전체 구성

- Image Captioning(IC): SubPJT1
- Text to Speech(TTS): SubPJT2



## Image Captioning

### 이미지 캡셔닝의 전체 학습 과정

- `데이터셋 준비 및 전처리 > 분류기 모델 설계 > Loss 함수 정의 > 모델 학습 > 특징 추출 > 캡션 결과 출력`



### 데이터셋 준비 및 전처리

`데이터셋 전처리`: 데이터 전처리는 기존의 데이터를 머신러닝 알고리즘에 알맞은 데이터로 바꾸는 과정

- 불 필요한 데이터 제거, 전체 속성 제거, 누락 데이터에 특정 값을 지정 등으로 데이터 가공(데이터 검수)

- 데이터셋(문자형, 이미지형 등)을 숫자형 데이터로 인코딩

- 이렇게 전환된 데이터는 다양한 범위ㅇ의 숫자형 데이터이기 때문에 바로 ML 알고리즘이 학습을 잘 하지 못함.

- 이를 위해 `Min-Max Scaling(Normalization)` 과정을 거침.

  - **최솟값과 최댓값을 확인하여 이 값들을 모두 지정한 범위(대체로 0과 1 사이)의 상대적인 값으로 변환시키는 방법입니다.**

    **특정 범위를 지정하면 해당 범위 안으로 바인딩시키는 방법입니다.**

    ![img](README.assets/img.png)

    

    출처: https://davinci-ai.tistory.com/15 [DAVINCI - AI]

  - 위 기능을 우리 프로젝트에서는 `torchvision`이 지원해줌.



### 분류기 모델 설계

`CNN(Convolutional neural network, 합성곱신경망)`:  정규화 된 버전의 다층 퍼셉트론이다. 다층 퍼셉트론은 일반적으로 완전히 연결된 네트워크, 즉 한 계층의 각 뉴런이 다음 계층의 모든 뉴런에 연결되는 신경망 구조

`전체 순서`: `데이터 탐색 > 모델 구성 > 모델 훈련 > 평가 > 예측하기`

